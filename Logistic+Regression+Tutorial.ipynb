{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a classification algorithm, donâ€™t confuse with the name regression. In classification problem the values we predict take on only a small number of discrete values. For example, \"yes or no\", \"cat or dog\", \"cat or dog or bird\", etc.\n",
    "In logistic regression we estimate the probability of a certain discrete value.\n",
    "\n",
    "Some examples of classification problems:\n",
    "1. Spam detection\n",
    "2. Detection of fraudulent transanctions\n",
    "3. Malignant/Benign tumor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis for classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification problem we want the probability of the outcomes. So we would like h(x) to be between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "0 \n",
    "\\leq \n",
    "h(x) \n",
    "\\leq \n",
    "1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function is used to restrict the h(x) between 0 and 1. Sigmoid function is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "sigmoid (x) = 1/(1 + \\exp (-x))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKjIkSJKkIkOCJEkq+n+nQd10xM3N4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5115f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Explore the signature of sigmoid function'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "     y = 1 / (1 + np.exp(-x))\n",
    "     return y\n",
    "\n",
    "xdata = np.arange(-10, 10)\n",
    "ydata = sigmoid(xdata)\n",
    "\n",
    "plt.plot(xdata, ydata, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function for a value of h(x):\n",
    "\n",
    "\\begin{equation}\n",
    "Cost (h(x),y)=\n",
    " \\begin{cases}%\n",
    "  -\\log (h(x))      & \\text{if $y=1$}\\\\\n",
    "  -\\log (1-h(x)) & \\text{if $y=0$}\\\\\n",
    " \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Which can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "Cost(h(x), y) = -y\\log(h(x))-(1-y)\\log(1-h(x))\n",
    "\\end{equation}\n",
    "\n",
    "The total cost function is the summation of cost generated in each sample of the data set.\n",
    "\n",
    "\\begin{equation}\n",
    "J = (-1/m) \\sum_{n=1}^{m} [y^{(i)} \\log(h(x^{(i)})) + (1-y^{(i)})\\log(1- h(x^{(i)}))]\n",
    "\\end{equation}\n",
    "\n",
    "The objective is similar to linear regression, minimize the cost function 'J'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intution of logistic regression\n",
    "\n",
    "Its about finding the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-344e72e85996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1 = np.random.randn(100)\n",
    "y1 = np.random.randn(100) \n",
    "x2 = np.random.randn(100)\n",
    "y2 = np.random.randn(100) + 6\n",
    "plt.plot(x1, y1, \"+\", x2, y2, \"x\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = np.random.randn(100)\n",
    "y1 = np.random.randn(100) + 3\n",
    "x2 = np.random.randn(100) + 3\n",
    "y2 = np.random.randn(100)\n",
    "plt.plot(x1, y1, \"+\", x2, y2, \"x\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = np.random.randn(100)\n",
    "y1 = np.random.randn(100) \n",
    "x3 = np.random.randn(25) + 3\n",
    "y3 = np.random.randn(25)\n",
    "x4 = np.random.randn(25) - 3\n",
    "y4 = np.random.randn(25)\n",
    "x5 = np.random.randn(25)\n",
    "y5 = np.random.randn(25) + 3\n",
    "x6 = np.random.randn(25) \n",
    "y6 = np.random.randn(25) - 3\n",
    "x3 = np.append(x3 , x5)\n",
    "y3 = np.append(y3, y5)\n",
    "x4 = np.append(x4, x6)\n",
    "y4 = np.append(y4, y6)\n",
    "x2 = np.append(x3, x4)\n",
    "y2 = np.append(y3, y4)\n",
    "#x2 = np.append(x3, x6)\n",
    "#y2 = np.append(y2 , y6)\n",
    "plt.plot(x1, y1, \"+\", x2, y2, \"x\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits classification example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Load the dataset from sklearn'''\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Print the size of the data set'''\n",
    "#print(\"Data set size: \")\n",
    "#print (\"Image Data Shape\", digits.data.shape)\n",
    "#print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the figures\n",
    "\n",
    "An image is represented by a matirx containing the pixel values of the image. The matrix has the same dimensions as the image. \n",
    "A colour image has 3 matrices covering Red, Green and Blue spectrum. A grey scale image has only one matrix with values between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray) # reshaping the image to 8 by 8 and specifying color map to grey scale\n",
    "    plt.title('y =: %i\\n' % label, fontsize = 20)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#classify_digits = LogisticRegression()\n",
    "#classify_digits.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Plot first 10 test images'''\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(9,4))\n",
    "for index, (image, label) in enumerate(zip(x_test[0:10], y_test[0:10])):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray) \n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Predict first test image'''  \n",
    "#classify_digits.predict(x_test[0].reshape(1,-1))\n",
    "\n",
    "'''Predict the first 10 test images''' \n",
    "#classify_digits.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Complete predicting the whole test set'''\n",
    "#predictions = classify_digits.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Score the prediction'''\n",
    "#score = classify_digits.score(x_test, y_test)\n",
    "#print(\"score = \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment - Machine Learning From Disaster\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.\n",
    "\n",
    "In this assignment you have to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply logistic regression to predict which passengers survived the tragedy.\n",
    "\n",
    "[This data has been download from Kaggle and modified to our requirement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Data'''\n",
    "\n",
    "'''Survival data; 1 - survived, 0 - did not survive'''\n",
    "y = np.array([ 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,])\n",
    "\n",
    "'''Passenger Number'''\n",
    "passenger = np.array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,])\n",
    "\n",
    "'''ticket: 3 - 3rd class, 2 - 2nd class, 1 - 1st class'''\n",
    "ticket = np.array([ 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 1, 2, 3, 2, 3, 3, 1, 1, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 2, 2, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 2, 3, 3, 2, 3, 1, 3, 3, 2, 2, 3, 2, 1, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 2, 1, 3, 2, 1, 2, 3, 2, 3, 1, 3, 2, 3, 2, 1, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 2, 1, 2, 3, 1, 3, 3, 3, 1, 1, 2, 3, 1, 1, 2, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 1, 2, 3, 3, 3, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 3, 2, 3, 2, 2, 1, 1, 3, 3, 2, 2, 1, 3, 2, 3, 1, 1, 1, 3, 1, 1, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 2, 3, 2, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 2, 3, 2, 2, 1, 3, 3, 1, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 1, 3, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 1, 2, 3, 1, 1, 3, 2, 1, 2, 2, 3, 3, 2, 1, 2, 1, 3, 1, 2, 1, 1, 3, 1, 2, 1, 3, 1, 2, 3, 1, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 2, 3, 3, 3, 1, 1, 3, 1, 2, 2, 3, 1, 3, 1, 3, 2, 3, 2, 2, 3, 3, 2, 1, 1, 1, 1, 3, 3, 2, 1, 1, 2, 3, 2, 1, 2, 3, 3, 1, 1, 1, 3, 3, 2, 3, 3, 3, 3, 2, 1, 1, 3, 3, 2, 1, 3, 2, 1, 2, 1, 1, 2, 1, 3, 3, 1, 3, 2, 3, 3, 1, 2, 3, 1, 3, 3, 1, 2, 1, 3, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 2, 1, 3, 1, 3, 1, 3, 2, 3, 2, 3, 3, 1, 3, 3, 1, 3, 1, 3, 2, 3, 3, 2, 3, 2, 1, 1, 3, 1, 3, 3, 2, 2, 3, 2, 1, 2, 2, 3, 3, 3, 3, 1, 1, 3, 3, 2, 2, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 3, 1, 1, 3, 3, 3, 2, 2, 1, 1, 1, 1, 3, 2, 3, 1, 2, 3, 2, 3, 2, 2, 1, 3, 2, 2, 3, 1, 3, 2, 2, 3, 3, 1, 1, 1, 3, 3, 1, 3, 2, 1, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 2, 2, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 1, 2, 3, 2, 1, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 3, 1, 3, 3, 2, 1, 3, 2, 3, 3, 1, 3, 3, 3, 2, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 1, 1, 3, 3, 2, 1, 2, 2, 2, 1, 3, 3, 1, 1, 3, 2, 3, 3, 3, 1, 2, 3, 3, 2, 3, 3, 2, 1, 1, 3,])\n",
    "\n",
    "'''ticket fare in dollars'''\n",
    "fare = np.array([ 7.25, 71.2833, 7.925, 53.1, 8.05, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16, 29.125, 18, 26, 13, 8.0292, 35.5, 21.075, 31.3875, 263, 27.7208, 10.5, 82.1708, 52, 8.05, 18, 11.2417, 9.475, 21, 41.5792, 7.8792, 17.8, 39.6875, 7.8, 76.7292, 26, 61.9792, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80, 83.475, 27.9, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 29, 12.475, 9, 9.5, 47.1, 10.5, 15.85, 34.375, 263, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 34.6542, 63.3583, 23, 26, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.8958, 52, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21, 247.5208, 31.275, 73.5, 30.0708, 13, 77.2875, 11.2417, 7.1417, 6.975, 7.8958, 7.05, 14.5, 26, 13, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26, 13, 12.525, 66.6, 8.05, 14.5, 61.3792, 7.7333, 8.05, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 27.9, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 28.7125, 13, 0, 31.3875, 39, 22.025, 26.55, 15.5, 7.8958, 13, 13, 7.8542, 26, 27.7208, 146.5208, 8.4042, 13, 9.5, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31, 7.05, 21, 7.25, 13, 113.275, 7.925, 27, 76.2917, 10.5, 8.05, 13, 8.05, 90, 9.35, 10.5, 7.25, 13, 83.475, 7.775, 13.5, 31.3875, 10.5, 26, 26.25, 10.5, 12.275, 10.5, 7.125, 7.225, 90, 7.775, 14.5, 52.5542, 26, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 86.5, 512.3292, 26, 31.3875, 79.65, 0, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 0, 19.5, 29.7, 77.9583, 7.75, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 8.6625, 9.5, 7.8958, 13, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 7.2292, 151.55, 247.5208, 0, 151.55, 108.9, 24, 56.9292, 83.1583, 262.375, 26, 7.8958, 26.25, 7.8542, 26, 14, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29, 135.6333, 6.2375, 13, 20.525, 57.9792, 28.5, 153.4625, 18, 66.6, 134.5, 8.05, 35.5, 26, 263, 13, 13, 13, 13, 13, 15.9, 8.6625, 9.225, 7.2292, 17.8, 9.5, 55, 13, 27.9, 27.7208, 14.4542, 7.05, 7.25, 75.25, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52, 73.5, 46.9, 13, 12, 120, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21, 7.75, 18.75, 7.775, 90, 7.925, 32.5, 13, 13, 24.15, 7.7333, 7.875, 14.4, 20.2125, 26, 26, 8.05, 26.55, 26, 7.125, 55.9, 120, 34.375, 18.75, 263, 10.5, 26.25, 9.5, 7.775, 13, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 27.75, 89.1042, 7.8958, 26.55, 10.5, 26.55, 8.05, 38.5, 13, 7.05, 26.55, 19.2583, 8.6625, 27.75, 13.7917, 9.8375, 21, 7.0458, 7.5208, 12.2875, 46.9, 8.05, 9.5875, 91.0792, 90, 29.7, 8.05, 15.9, 7.25, 30.5, 49.5042, 8.05, 78.2667, 151.55, 7.7958, 8.6625, 7.75, 9.5875, 86.5, 108.9, 26, 22.525, 56.4958, 7.75, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 26, 7.8958, 93.5, 7.8958, 57.9792, 7.75, 10.5, 7.925, 11.5, 26, 7.2292, 8.6625, 26.25, 26.55, 106.425, 49.5, 71, 31.275, 31.275, 26, 106.425, 26, 26, 20.525, 36.75, 110.8833, 26, 7.225, 7.775, 26.55, 39.6, 79.65, 17.4, 7.8958, 13.5, 24.15, 7.8958, 21.075, 7.8542, 10.5, 51.4792, 26.3875, 8.05, 14.5, 13, 55.9, 7.925, 30, 110.8833, 26, 40.125, 79.65, 15, 79.2, 8.05, 7.125, 78.2667, 7.25, 26, 24.15, 0, 56.9292, 27, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 8.05, 65, 14.4, 16.1, 39, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 30, 7.0542, 30.5, 27.9, 13, 7.925, 26.25, 39.6875, 7.8542, 69.3, 27.9, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 23, 8.4333, 6.75, 73.5, 15.5, 13, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13, 8.05, 39, 52, 10.5, 13, 7.775, 8.05, 9.8417, 46.9, 512.3292, 76.7292, 9.225, 46.9, 39, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57, 13.4167, 7.225, 26.55, 13.5, 8.05, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26, 13.5, 26.2875, 151.55, 49.5042, 52, 9.4833, 13, 7.65, 227.525, 10.5, 7.775, 33, 7.0542, 13, 13, 53.1, 8.6625, 21, 26, 7.925, 211.3375, 18.7875, 13, 13, 16.1, 34.375, 512.3292, 78.85, 262.375, 16.1, 7.925, 71, 20.25, 13, 53.1, 7.75, 23, 12.475, 9.5, 7.8958, 65, 14.5, 7.7958, 11.5, 8.05, 86.5, 7.125, 7.2292, 120, 7.775, 77.9583, 7.75, 8.3625, 9.5, 7.8542, 10.5, 23, 7.75, 12.475, 211.3375, 7.2292, 57, 30, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 26, 7.8958, 13, 25.9292, 8.6833, 7.2292, 24.15, 13, 26.25, 120, 8.5167, 6.975, 7.775, 0, 7.775, 13, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0, 12.475, 39.6875, 37.0042, 80, 14.4542, 18.75, 7.8542, 8.3, 83.1583, 8.6625, 56.4958, 7.925, 10.5, 31, 6.4375, 8.6625, 7.55, 7.8958, 33, 31.275, 7.775, 15.2458, 39.4, 26, 9.35, 164.8667, 26.55, 19.2583, 14.1083, 11.5, 25.9292, 13, 13, 13.8583, 50.4958, 11.1333, 7.8958, 52.5542, 5, 9, 24, 7.225, 9.8458, 7.8958, 83.1583, 26, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13, 30, 30, 7.75,])\n",
    "\n",
    "'''Sex: 0 - male, 1 - female'''\n",
    "sex = np.array([ 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,])\n",
    "\n",
    "'''Age'''\n",
    "age = np.array([ 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, 2, 31, 35, 34, 15, 28, 8, 38, 19, 40, 66, 28, 42, 21, 18, 14, 40, 27, 3, 19, 18, 7, 21, 49, 29, 65, 21, 28.5, 5, 11, 22, 38, 45, 4, 29, 19, 17, 26, 32, 16, 21, 26, 32, 25, .83, 30, 22, 29, 28, 17, 33, 16, 23, 24, 29, 20, 46, 26, 59, 71, 23, 34, 34, 28, 21, 33, 37, 28, 21, 38, 47, 14.5, 22, 20, 17, 21, 70.5, 29, 24, 2, 21, 32.5, 32.5, 54, 12, 24, 45, 33, 20, 47, 29, 25, 23, 19, 37, 16, 24, 22, 24, 19, 18, 19, 27, 9, 36.5, 42, 51, 22, 55.5, 40.5, 51, 16, 30, 44, 40, 26, 17, 1, 9, 45, 28, 61, 4, 1, 21, 56, 18, 50, 30, 36, 9, 1, 4, 45, 40, 36, 32, 19, 19, 3, 44, 58, 42, 24, 28, 34, 45.5, 18, 2, 32, 26, 16, 40, 24, 35, 22, 30, 31, 27, 42, 32, 30, 16, 27, 51, 38, 22, 19, 20.5, 18, 35, 29, 59, 5, 24, 44, 8, 19, 33, 29, 22, 30, 44, 25, 24, 37, 54, 29, 62, 30, 41, 29, 30, 35, 50, 3, 52, 40, 36, 16, 25, 58, 35, 25, 41, 37, 63, 45, 7, 35, 65, 28, 16, 19, 33, 30, 22, 42, 22, 26, 19, 36, 24, 24, 23.5, 2, 50, 19, .92, 17, 30, 30, 24, 18, 26, 28, 43, 26, 24, 54, 31, 40, 22, 27, 30, 22, 36, 61, 36, 31, 16, 45.5, 38, 16, 29, 41, 45, 45, 2, 24, 28, 25, 36, 24, 40, 3, 42, 23, 15, 25, 28, 22, 38, 40, 29, 45, 35, 30, 60, 24, 25, 18, 19, 22, 3, 22, 27, 20, 19, 42, 1, 32, 35, 18, 1, 36, 17, 36, 21, 28, 23, 24, 22, 31, 46, 23, 28, 39, 26, 21, 28, 20, 34, 51, 3, 21, 33, 44, 34, 18, 30, 10, 21, 29, 28, 18, 28, 19, 32, 28, 42, 17, 50, 14, 21, 24, 64, 31, 45, 20, 25, 28, 4, 13, 34, 5, 52, 36, 30, 49, 29, 65, 50, 48, 34, 47, 48, 38, 56, .75, 38, 33, 23, 22, 34, 29, 22, 2, 9, 50, 63, 25, 35, 58, 30, 9, 21, 55, 71, 21, 54, 25, 24, 17, 21, 37, 16, 18, 33, 28, 26, 29, 36, 54, 24, 47, 34, 36, 32, 30, 22, 44, 40.5, 50, 39, 23, 2, 17, 30, 7, 45, 30, 22, 36, 9, 11, 32, 50, 64, 19, 33, 8, 17, 27, 22, 22, 62, 48, 39, 36, 40, 28, 24, 19, 29, 32, 62, 53, 36, 16, 19, 34, 39, 32, 25, 39, 54, 36, 18, 47, 60, 22, 35, 52, 47, 37, 36, 49, 49, 24, 44, 35, 36, 30, 27, 22, 40, 39, 35, 24, 34, 26, 4, 26, 27, 42, 20, 21, 21, 61, 57, 21, 26, 80, 51, 32, 9, 28, 32, 31, 41, 20, 24, 2, .75, 48, 19, 56, 23, 18, 21, 18, 24, 32, 23, 58, 50, 40, 47, 36, 20, 32, 25, 43, 40, 31, 70, 31, 18, 24.5, 18, 43, 36, 27, 20, 14, 60, 25, 14, 19, 18, 15, 31, 4, 25, 60, 52, 44, 49, 42, 18, 35, 18, 25, 26, 39, 45, 42, 22, 24, 48, 29, 52, 19, 38, 27, 33, 6, 17, 34, 50, 27, 20, 30, 25, 25, 29, 11, 23, 23, 28.5, 48, 35, 36, 21, 24, 31, 70, 16, 30, 19, 31, 4, 6, 33, 23, 48, .67, 28, 18, 34, 33, 41, 20, 36, 16, 51, 30.5, 32, 24, 48, 57, 54, 18, 5, 43, 13, 17, 29, 25, 25, 18, 8, 1, 46, 16, 25, 39, 49, 31, 30, 30, 34, 31, 11, .42, 27, 31, 39, 18, 39, 33, 26, 39, 35, 6, 30.5, 23, 31, 43, 10, 52, 27, 38, 27, 2, 1, 62, 15, .83, 23, 18, 39, 21, 32, 20, 16, 30, 34.5, 17, 42, 35, 28, 4, 74, 9, 16, 44, 18, 45, 51, 24, 41, 21, 48, 24, 42, 27, 31, 4, 26, 47, 33, 47, 28, 15, 20, 19, 56, 25, 33, 22, 28, 25, 39, 27, 19, 26, 32,])\n",
    "\n",
    "'''No of Parents on board'''\n",
    "parents = np.array([ 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,])\n",
    "\n",
    "'''No of Siblings on board'''\n",
    "siblings = np.array([ 1, 0, 0, 0, 0,-1, 3, 0, 1, 1,-1, 0, 0, 0,-1, 4, 0, 0, 0, 0, 0, 3, 0, 3,-1,-1, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 4, 0, 0, 0,-1, 0, 0, 1, 5, 0,-1, 0, 3, 0, 0, 4, 2, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1,-1,-1, 0, 0, 0, 0, 0, 0, 1, 0, 0,-1,-1, 1, 0, 1, 0, 0,-1, 0, 0, 4, 2, 0, 0,-1, 1, 0,-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2,-1,-1,-1, 1,-1,-1,-1, 0, 0,-1,-1, 0, 0, 4, 0, 0, 0,-1, 4, 1, 0,-1, 1,-1, 0,-1, 4, 2, 0,-1, 0,-1, 0, 0, 1, 1,-1,-1,-1, 0, 0, 0,-1, 0, 0, 0, 0, 0,-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,-1, 0, 0, 0, 0, 0, 0, 0,-1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,-1, 0,-1, 0, 0, 0,-1, 4, 0,-1,-1, 4, 1,-1, 0, 0,-1,-1, 0,-1, 4, 0,-1, 0, 0, 0, 0, 0, 0,-1, 0, 0, 1,-1, 0, 0, 0, 1,-1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1,-1, 0, 0, 0, 0, 0, 1,-1,-1,-1, 0, 0,-1,-1, 2, 0,-1,-1,-1, 1, 3, 0, 0,-1, 0,-1, 1,-1, 0, 1, 1, 0, 0,-1, 0, 0,-1, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 0,-1, 0, 0, 0, 0, 5,-1, 0, 0, 0, 2, 1, 0, 0, 0,-1, 0, 0,-1, 0, 1, 1, 0, 0,-1, 1, 0, 0,-1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2,-1, 0, 0, 0, 0,-1,-1,-1, 0,-1,-1,-1,-1, 2,-1, 0, 0, 0, 0, 0, 0, 0, 5,-1,-1, 1, 0,-1, 0, 1, 0,-1,-1, 0, 0, 1, 0, 0, 0,-1, 0, 1, 0, 0, 0, 0,-1, 0, 0,-1, 0, 0, 0, 0, 0,-1,-1,-1,-1, 2, 1, 1, 0, 0,-1, 0, 0,-1, 4, 4, 0, 0,-1, 1, 0, 1, 0, 0, 0, 0,-1, 0, 0, 0,-1, 0, 2, 0, 0, 0,-1, 1,-1, 0, 0, 0, 0, 0, 1, 0,-1,-1, 0,-1, 0, 0, 0, 0,-1, 0, 0,-1, 0, 2,-1, 0, 0, 0, 0, 1,-1, 0, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 0,-1,-1, 0, 0,-1,-1, 0, 3, 0, 0, 0,-1, 0, 0, 3, 2, 0, 0,-1, 0, 0, 0, 0, 2, 0, 0,-1, 1,-1,-1,-1, 1, 0, 0,-1, 0, 0,-1, 0, 0, 0, 0, 0,-1, 0, 0, 5, 0, 1, 4, 0, 0, 0, 0, 0, 0,-1,-1,-1, 0,-1, 1, 0, 0, 0, 1,-1,-1,-1, 0, 0, 0, 0,-1, 0,-1, 0, 0, 0, 1, 0,-1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,-1, 0, 0, 0, 0, 0, 0, 0,-1,-1, 0, 0, 0,-1, 0, 1, 0, 0, 0, 0, 4, 1,-1, 0, 0,-1,-1, 0, 0, 0, 0, 0, 1, 0, 0, 0,-1, 0,-1, 0, 0,-1, 0, 4, 0, 0, 0,-1, 3, 0, 0,-1, 0, 4, 0,-1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,-1, 0, 0, 4,-1, 1, 0, 0, 0, 0,-1, 0, 1, 1,-1, 0,-1, 1, 0, 1, 0, 0, 0,-1, 1, 0, 0, 0,-1, 0, 0, 0, 0, 0,-1, 0, 0, 0, 0,])\n",
    "\n",
    "'''Embark port: 1 = Southampton, 2 = Cherbourg, 3 = Queenstown, '''\n",
    "embark = np.array([ 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 3, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3,])\n",
    "\n",
    "'''Number of Children on board'''\n",
    "children = np.array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### useful syntax: \n",
    "\n",
    "_column stack_\n",
    "\n",
    "a = np.array((1,2,3))\n",
    "\n",
    "b = np.array((2,3,4))\n",
    "\n",
    "np.column_stack((a,b))\n",
    "\n",
    "output:\n",
    "array([[1, 2],\n",
    "       [2, 3],\n",
    "       [3, 4]])\n",
    "\n",
    "_add_\n",
    "\n",
    "np.add (a,b)\n",
    "\n",
    "output:\n",
    "array([3, 5, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "More about sklearn - logistic regression:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "13d62f4d-cdcb-455c-bfbf-705c79ada11f": {
     "id": "13d62f4d-cdcb-455c-bfbf-705c79ada11f",
     "prev": "9c286f1c-da95-4b4b-8285-753ee69bb757",
     "regions": {
      "b9231280-1180-435b-9948-5b24fa4a6b69": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dc2ab5b6-a772-45ae-9766-5d99ffdc6289",
        "part": "whole"
       },
       "id": "b9231280-1180-435b-9948-5b24fa4a6b69"
      }
     }
    },
    "9c286f1c-da95-4b4b-8285-753ee69bb757": {
     "id": "9c286f1c-da95-4b4b-8285-753ee69bb757",
     "prev": null,
     "regions": {
      "31d6daba-1aaf-4985-a91c-1ef402689838": {
       "attrs": {
        "height": 0.7999999999999999,
        "width": 0.799997417355372,
        "x": 0.10000025826446282,
        "y": 0.09999999999999999
       },
       "content": {
        "cell": "7f2c38ea-2371-495f-a992-88fe5ec3cb18",
        "part": "whole"
       },
       "id": "31d6daba-1aaf-4985-a91c-1ef402689838"
      }
     }
    },
    "deda7c58-04b6-40ad-8d57-d42fbe6082d4": {
     "id": "deda7c58-04b6-40ad-8d57-d42fbe6082d4",
     "prev": "13d62f4d-cdcb-455c-bfbf-705c79ada11f",
     "regions": {
      "3add0ea1-7ff8-4665-82e5-bb6b73c214cc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a29a979f-21c7-4553-a7af-eaf0f0085351",
        "part": "whole"
       },
       "id": "3add0ea1-7ff8-4665-82e5-bb6b73c214cc"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
